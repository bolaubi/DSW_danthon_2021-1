{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correct-structure",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV, train_test_split, StratifiedKFold\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, plot_precision_recall_curve, plot_roc_curve, roc_curve, confusion_matrix\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, KBinsDiscretizer\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sophisticated-satellite",
   "metadata": {},
   "source": [
    "## Continue modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foreign-equivalent",
   "metadata": {},
   "outputs": [],
   "source": [
    "ready = pd.read_csv('new_ready.csv').drop(['lat', 'lon'],axis=1)\n",
    "ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explicit-sentence",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('new_test.csv')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plain-filing",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = 'x y z day month hour_y'.split()\n",
    "label = 'Labels'\n",
    "\n",
    "X = ready[features]\n",
    "y = ready[label]\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, stratify=y, random_state=24, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-progress",
   "metadata": {},
   "outputs": [],
   "source": [
    "kbins = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')\n",
    "\n",
    "transformer = ColumnTransformer([\n",
    "        ('poly', PolynomialFeatures(degree=2, include_bias=False), ['x','y','z']),\n",
    "        ('kbins', kbins, ['day','hour_y'])\n",
    "], remainder='passthrough')\n",
    "\n",
    "logit_smo = Pipeline([\n",
    "    ('trans', transformer),\n",
    "    ('smote', SMOTE(random_state=2020)),\n",
    "    ('clf', LogisticRegression(random_state=2020))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-policy",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_space = {\n",
    "    'trans__poly__degree': [2,3],\n",
    "    'smote__k_neighbors': [3,4,5],\n",
    "    'clf__C': [0.01,0.1,1],\n",
    "    'clf__solver': ['lbfgs', 'liblinear']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinate-settle",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold()\n",
    "\n",
    "logit_grid = GridSearchCV(\n",
    "    logit_smo,\n",
    "    param_grid=param_space,\n",
    "    scoring='f1',\n",
    "    cv = skf,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legal-basement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logit_grid.fit(X_train_val, y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-sydney",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-colony",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_tuned = logit_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "processed-aurora",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_tuned.fit(X_train_val, y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "violent-fellowship",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_smo.fit(X_train_val, y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drawn-toilet",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_tuned_pred = logit_tuned.predict(X_test)\n",
    "print(classification_report(y_test, logit_tuned_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ambient-deposit",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_pred = logit_smo.predict(X_test)\n",
    "print(classification_report(y_test, logit_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thick-disease",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(logit_tuned, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-pearl",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_prob1 = logit_tuned.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, thr = roc_curve(y_test, logit_prob1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "voluntary-geometry",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_df = pd.DataFrame({'fpr': fpr, 'tpr': tpr, 'thr': thr})\n",
    "roc_df[roc_df['tpr'].between(0.8, 0.9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "taken-fountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_thr = 0.371134\n",
    "y_pred037 = np.where(logit_tuned.predict_proba(X_test)[:,1]>new_thr,1,0)\n",
    "print(classification_report(y_test, y_pred037))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-processing",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred037)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minimal-english",
   "metadata": {},
   "source": [
    "## VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cross-teach",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier(max_depth=10, min_samples_split=100)\n",
    "# dtc_cal = CalibratedClassifierCV(dtc, method='isotonic')\n",
    "\n",
    "# GaussianNB\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# VotingClassifier\n",
    "vclf = VotingClassifier([('logit',logit_tuned), ('dtc', dtc), ('gaussian', gnb)], voting='soft', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-mineral",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-consultancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_space_vclf = {\n",
    "    'dtc__max_depth': [10,20],\n",
    "    'dtc__min_samples_split': [100, 200],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-credit",
   "metadata": {},
   "outputs": [],
   "source": [
    "vclf_grid = GridSearchCV(\n",
    "    vclf,\n",
    "    param_grid=param_space_vclf,\n",
    "    scoring='f1',\n",
    "    cv = skf,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    " )\n",
    "\n",
    "vclf_grid.fit(X_train_val, y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-calibration",
   "metadata": {},
   "outputs": [],
   "source": [
    "vclf_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-harvard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecisionTreeClassifier\n",
    "dtc_tuned = DecisionTreeClassifier(max_depth=20, min_samples_split=100, class_weight='balanced')\n",
    "# dtc_cal = CalibratedClassifierCV(dtc, method='isotonic')\n",
    "\n",
    "# GaussianNB\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# VotingClassifier\n",
    "vclf_tuned = VotingClassifier([('logit',logit_tuned), ('dtc', dtc_tuned), ('gaussian', gnb)], voting='soft', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biblical-dover",
   "metadata": {},
   "outputs": [],
   "source": [
    "vclf_tuned.fit(X_train_val, y_train_val)\n",
    "print('done fitting!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wireless-entrepreneur",
   "metadata": {},
   "outputs": [],
   "source": [
    "vclf_pred_tuned = vclf_tuned.predict(X_test)\n",
    "print(classification_report(y_test, vclf_pred_tuned))\n",
    "display(confusion_matrix(y_test, vclf_pred_tuned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hawaiian-strip",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(vclf_tuned, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automatic-translation",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thr = roc_curve(y_test, vclf_tuned.predict_proba(X_test)[:,1])\n",
    "roc_df = pd.DataFrame({'fpr': fpr, 'tpr': tpr, 'thr': thr})\n",
    "roc_df[roc_df['tpr'].between(0.95, 1.0)].sort_values('fpr').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-layer",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_thr = 0.567104\n",
    "y_pred0567 = np.where(vclf_tuned.predict_proba(X_test)[:,1]>new_thr,1,0)\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred0567))\n",
    "display(confusion_matrix(y_test, y_pred0567))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cheap-sunset",
   "metadata": {},
   "outputs": [],
   "source": [
    "vclf_tuned.fit(X,y)\n",
    "submit = vclf_tuned.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nasty-junction",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(submit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valuable-poultry",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_submit = pd.read_csv('data_test.csv')\n",
    "test_submit['Labels'] = submit\n",
    "\n",
    "test_submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solar-poultry",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_submit.to_csv('submit2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beginning-firmware",
   "metadata": {},
   "source": [
    "## Try another technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlike-smart",
   "metadata": {},
   "outputs": [],
   "source": [
    "ready_clean = pd.read_csv('ready_clean.csv')\n",
    "db_street = pd.read_csv('db_street.csv')\n",
    "db_road_type = pd.read_csv('db_road_type.csv')\n",
    "db_jam_level = pd.read_csv('db_jam_level.csv')\n",
    "ready_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlike-liabilities",
   "metadata": {},
   "outputs": [],
   "source": [
    "ready = pd.read_csv('ready.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functional-egypt",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ids_to_df(df):\n",
    "    test_df2 = pd.DataFrame()\n",
    "    test_df2['s2cell_token'] = df['Ids'].str.split('_').apply(lambda x: x[0])\n",
    "    test_df2['date'] = df['Ids'].str.split('_').apply(lambda x: x[1])\n",
    "    test_df2['date'] = test_df2['date'].str.split('-')\n",
    "    test_df2['hour'] = df['Ids'].str.split('_').apply(lambda x: x[2])\n",
    "    \n",
    "    test_df2['year'] = test_df2['date'].apply(lambda x: int(x[0]))\n",
    "    test_df2['month'] = test_df2['date'].apply(lambda x: int(x[1]))\n",
    "    test_df2['day'] = test_df2['date'].apply(lambda x: int(x[2]))\n",
    "    test_df2['hour'] = test_df2['hour'].astype('int')\n",
    "    \n",
    "    test_df2['lat'] = test_df2['s2cell_token'].apply(s2cell.token_to_lat_lon).apply(lambda x: x[0])\n",
    "    test_df2['lon'] = test_df2['s2cell_token'].apply(s2cell.token_to_lat_lon).apply(lambda x: x[1])\n",
    "    \n",
    "    test_df2['x'] = np.cos(test_df2['lat']) * np.cos(test_df2['lon'])\n",
    "    test_df2['y'] = np.cos(test_df2['lat']) * np.sin(test_df2['lon'])\n",
    "    test_df2['z'] = np.sin(test_df2['lat'])\n",
    "    \n",
    "    test_df2 = test_df2[['x', 'y', 'z', 'day', 'month', 'hour']]\n",
    "    \n",
    "    return test_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jewish-snapshot",
   "metadata": {},
   "outputs": [],
   "source": [
    "ready_clean['x'] = np.cos(ready_clean['lat']) * np.cos(ready_clean['lon'])\n",
    "ready_clean['y'] = np.cos(ready_clean['lat']) * np.sin(ready_clean['lon'])\n",
    "ready_clean['z'] = np.sin(ready_clean['lat'])\n",
    "ready_clean.drop(['lat', 'lon'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-dover",
   "metadata": {},
   "outputs": [],
   "source": [
    "ready_clean.drop('s2token_15', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excess-louis",
   "metadata": {},
   "outputs": [],
   "source": [
    "ready_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "architectural-imperial",
   "metadata": {},
   "outputs": [],
   "source": [
    "ready_clean.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "danish-staff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary\n",
    "ready_clean['street_y'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protecting-therapy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multiple-veteran",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = ColumnTransformer([\n",
    "    ('binary', ce.BinaryEncoder(), ['street_y']),\n",
    "    ('poly', PolynomialFeatures(degree=3), ['x', 'y', 'z']),\n",
    "    ('kbins', KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform'), ['day', 'hour_y'])\n",
    "], remainder='passthrough')\n",
    "\n",
    "logit_new_pipe = Pipeline([\n",
    "    ('trans', transformer),\n",
    "    ('fs', RFE(LogisticRegression(C=0.01, solver='liblinear', random_state=2020, verbose=1, class_weight='balanced'))),\n",
    "    ('clf', LogisticRegression(C=0.01, solver='liblinear', random_state=2020, verbose=1, class_weight='balanced'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "placed-cedar",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ready_clean['x y z day month hour_y street_y road_type jam_level'.split()]\n",
    "y = np.where(ready_clean['Labels']==True,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automatic-bernard",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, stratify=y, test_size=.2, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-patient",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-water",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "presidential-intranet",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_new_pipe.fit(X_train_val, y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twelve-departure",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(logit_new_pipe, 'logit_new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polished-google",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_new_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accompanied-viewer",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logit_new_pipe.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corresponding-chassis",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaningful-school",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(logit_new_pipe, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-magnitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "# joblib.dump(logit_new_pipe, 'logit_new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-split",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_new = joblib.load('logit_new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informative-collapse",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mineral-chemical",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob1 = logit_new.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-merchant",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thr = roc_curve(y_test, y_prob1)\n",
    "roc_df = pd.DataFrame({'fpr': fpr, 'tpr': tpr, 'thr': thr})\n",
    "roc_df[roc_df['tpr'].between(0.95,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "robust-obligation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.889415 macro 0.67\n",
    "# 0.875739 macro 0.67\n",
    "# 0.797893 macro 0.74\n",
    "\n",
    "new_thr = 0.206125\n",
    "\n",
    "y_pred088 = np.where(logit_new.predict_proba(X_test)[:,1]>new_thr,1,0)\n",
    "print(classification_report(y_test, y_pred088))\n",
    "display(confusion_matrix(y_test, y_pred088))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-assistant",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_logit = logit_new.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-horse",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sufficient-mechanism",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-challenge",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test = pd.read_csv('test_set.csv')\n",
    "new_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-narrative",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selective-forth",
   "metadata": {},
   "outputs": [],
   "source": [
    "import s2cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rolled-absence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ids_to_df(df):\n",
    "    test_df2 = pd.DataFrame()\n",
    "    test_df2['s2cell_token'] = df['Ids'].str.split('_').apply(lambda x: x[0])\n",
    "    test_df2['date'] = df['Ids'].str.split('_').apply(lambda x: x[1])\n",
    "    test_df2['date'] = test_df2['date'].str.split('-')\n",
    "    test_df2['hour_y'] = df['Ids'].str.split('_').apply(lambda x: x[2])\n",
    "    test_df2['token_hour'] = test_df2['s2cell_token']+'_'+test_df2['hour_y'] \n",
    "    \n",
    "    test_df2['year'] = test_df2['date'].apply(lambda x: int(x[0]))\n",
    "    test_df2['month'] = test_df2['date'].apply(lambda x: int(x[1]))\n",
    "    test_df2['day'] = test_df2['date'].apply(lambda x: int(x[2]))\n",
    "    test_df2['hour_y'] = test_df2['hour_y'].astype('int')\n",
    "    \n",
    "    test_df2['lat'] = test_df2['s2cell_token'].apply(s2cell.token_to_lat_lon).apply(lambda x: x[0])\n",
    "    test_df2['lon'] = test_df2['s2cell_token'].apply(s2cell.token_to_lat_lon).apply(lambda x: x[1])\n",
    "    \n",
    "    test_df2['x'] = np.cos(test_df2['lat']) * np.cos(test_df2['lon'])\n",
    "    test_df2['y'] = np.cos(test_df2['lat']) * np.sin(test_df2['lon'])\n",
    "    test_df2['z'] = np.sin(test_df2['lat'])\n",
    "    \n",
    "    test_df2 = test_df2[['token_hour', 'x', 'y', 'z', 'day', 'month', 'hour_y']]\n",
    "    \n",
    "    return test_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-serve",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test = ids_to_df(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attempted-antibody",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curious-manhattan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# db_street\n",
    "# db_road_type\n",
    "# db_jam_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relevant-trace",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_street = pd.merge(new_test, db_street, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convinced-aircraft",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_road = pd.merge(merge_street, db_road_type, how='left')\n",
    "merge_road"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accredited-alfred",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_jam_level = pd.merge(merge_road, db_jam_level, how='left')\n",
    "merge_jam_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "external-french",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_jam_level.isna().sum()/len(merge_jam_level)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impaired-north",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_jam_level[['street_y', 'road_type', 'jam_level']].describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lonely-testimony",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_jam_level['street_y'].fillna(value='Cibarusah Raya', inplace=True)\n",
    "merge_jam_level['road_type'].fillna(value=2, inplace=True)\n",
    "merge_jam_level['jam_level'].fillna(value=3, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rational-realtor",
   "metadata": {},
   "outputs": [],
   "source": [
    "bismillah = merge_jam_level.drop(['Unnamed: 0', 's2token_15'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "micro-candle",
   "metadata": {},
   "outputs": [],
   "source": [
    "bismillah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knowing-robert",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifth-yesterday",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_thr = 0.206125\n",
    "\n",
    "bismillah['Labels'] = np.where(logit_new.predict_proba(bismillah)[:,1]>new_thr,True,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "canadian-logging",
   "metadata": {},
   "outputs": [],
   "source": [
    "bismillah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-romantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv('data_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-broadcasting",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['Labels'] = bismillah['Labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-positive",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.to_csv('submit3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blank-saver",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "waiting-hepatitis",
   "metadata": {},
   "source": [
    "## Using XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expressed-disability",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.feature_selection import SequentialFeatureSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "united-istanbul",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excellent-system",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-lancaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = ColumnTransformer([\n",
    "    ('poly', PolynomialFeatures(degree=3), ['x', 'y', 'z', 'speed_decrease_%']),\n",
    "    ('kbins', KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform'), ['day', 'hour_y'])\n",
    "], remainder='passthrough')\n",
    "\n",
    "xgb_pipe = Pipeline([\n",
    "    ('trans', transformer),\n",
    "    ('fs', RFE(DecisionTreeClassifier(max_depth=200, min_samples_split=100, max_features='sqrt', random_state=2020))),\n",
    "    ('clf', XGBClassifier(n_estimators=100, use_label_encoder=False, max_depth = 200, learning_rate=0.1, verbosity=2, booster='gbtree', n_jobs=-1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hawaiian-establishment",
   "metadata": {},
   "outputs": [],
   "source": [
    "ready['x'] = np.cos(ready['lat']) * np.cos(ready['lon'])\n",
    "ready['y'] = np.cos(ready['lat']) * np.sin(ready['lon'])\n",
    "ready['z'] = np.sin(ready['lat'])\n",
    "ready.drop(['lat', 'lon'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invisible-radical",
   "metadata": {},
   "outputs": [],
   "source": [
    "ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "choice-adrian",
   "metadata": {},
   "outputs": [],
   "source": [
    "ready.rename(columns={'speed_decreasement_%':'speed_decrease_%'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unknown-procedure",
   "metadata": {},
   "outputs": [],
   "source": [
    "ready.duplicated('s2token_15').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "dutch-hello",
   "metadata": {},
   "outputs": [],
   "source": [
    "ready.to_csv('ready_speed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outside-physics",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ready['x y z day month hour_y road_type jam_level speed_decrease_%'.split()]\n",
    "y = np.where(ready['Labels']==True,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporated-shipping",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X,y,test_size=.2,stratify=y,random_state=2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-rwanda",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pipe.fit(X_train_val, y_train_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noted-concert",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
